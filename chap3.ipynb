{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chap3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNxnIx1s0sOduNKn8F2bpPA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tonge-Shim/pytorchstudy/blob/main/chap3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkVV3ArBT1fP"
      },
      "source": [
        "# This chapter covers...\n",
        "> understanding tensors, the basic data structure\n",
        "\n",
        "> indexing / operating on tensors\n",
        "\n",
        "> interoperating with NumPy multidimensional arrays\n",
        "\n",
        "> moving computations to the gpu for speed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORGb19ciUS38"
      },
      "source": [
        "***Intermediate representaions***: collections of floating-point numbers that characterize the input and capture the data's structure in a way that is instrumental for describing how inputs are mapped to the outputs of the neural network.\n",
        "> IR이라고도 하며, 입력을 characterize, 데이터의 구조를 포착하는 소수점들의 집합이라고 할 수 있다. \n",
        "\n",
        "> 각 input에 unique한 ir이 존재한다. \n",
        "\n",
        "***Tensors*** : refer to the generalization of vectors and matrices to an arbitrary number of dimensions. (multidimensional array)\n",
        "\n",
        "***power** of pytorch tensors?...*\n",
        "> ability to perform very fast operations on graphical processing units(GPUs)\n",
        "\n",
        "> distribute operations on multiple devices or machines, and keep track of the graph of computations that created them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC5-5nOHzzV5"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiJc9wZncZJm",
        "outputId": "a4ae578e-614a-497e-fe63-2b96cdd2ff50"
      },
      "source": [
        "a = torch.ones(3)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reIePvyRciFP",
        "outputId": "f63ed165-4cda-420c-979e-50f248077359"
      },
      "source": [
        "a[2] = 2.0\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdKkRylI41wH"
      },
      "source": [
        "#*Indexing Tensors*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WVdb2HI402f",
        "outputId": "e994196a-7fb9-40b2-e7f1-5e12bfb9ad47"
      },
      "source": [
        "some_list = list(range(6))\n",
        "some_list [:] #all\n",
        "some_list[1:4]#1 inclusive 4 exclusive\n",
        "some_list[1:] # from 1 to end\n",
        "some_list[:4] # from the start of the list to element 4 exclusive\n",
        "some_list[:-1] # from the start of the list to one before the last element\n",
        "some_list[1:4:2] #1 inclusive to element 4 exclusive in steps of 2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqDioQixz8Z9",
        "outputId": "c6c8ec61-6d2c-4cb3-bebb-5b584a63180e"
      },
      "source": [
        "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])#2d tensor\n",
        "points"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4., 1.],\n",
              "        [5., 3.],\n",
              "        [2., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv5Hj-9g0JTI",
        "outputId": "fc80839b-ebf9-453d-8247-94de7f963bd5"
      },
      "source": [
        "points[None]# adding a dimension"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[4., 1.],\n",
              "         [5., 3.],\n",
              "         [2., 1.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec4ZzGlH8gn9"
      },
      "source": [
        "#*named tensors*\n",
        "\n",
        "기존의 tensor가 이미 있고, 이름을 붙이고 싶을 때 refine_names 함수로 실행가능하다.\n",
        "- ...(ellipsis)로 차원을 남겨둘 수 있다.\n",
        "- rename 이라는 sibling method로 기존의 이름들을 덮어쓰거나 drop(by passing None) 가능하다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0LCWsjG9xoz",
        "outputId": "ad750c4e-1c7b-4cea-8b95-814e7c29efaa"
      },
      "source": [
        "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names = ['channels'])\n",
        "weights_named"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:930.)\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6BY7dTQ1JRc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1586d57-3d3c-405f-fe91-ac8ac9339fba"
      },
      "source": [
        "img_t = torch.randn(3,5,5)\n",
        "weights = torch.tensor([0.2126, 0.7152, 0.0722])\n",
        "batch_t = torch.randn(2,3,5,5)\n",
        "img_named = img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
        "batch_named = batch_t.refine_names(..., 'channels', 'rows', 'columns')\n",
        "print(\"img named: \", img_named.shape, img_named.names)\n",
        "print(\"batch named: \", batch_named.shape, batch_named.names)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "img named:  torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n",
            "batch named:  torch.Size([2, 3, 5, 5]) (None, 'channels', 'rows', 'columns')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt_eHvPp-5PG"
      },
      "source": [
        "- the method \"**align_as**\" returns a tensor with missing dimensions added and existing ones permuted to the right order\n",
        "- **sum**: take named dimensions(accepts dimension arguments)\n",
        "- if we want to use tensors outside functions that operate on named tensors, we need to drop the name by renaming them to None.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxQxnBIQ_QvB",
        "outputId": "c2edcbe5-73b6-4ec0-f5b8-85d5328711e3"
      },
      "source": [
        "weights_aligned = weights_named.align_as(img_named)\n",
        "weights_aligned.shape, weights_aligned.names\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 1, 1]), ('channels', 'rows', 'columns'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP9u9owIASpZ",
        "outputId": "5e7140dc-b01d-4d84-c78d-a5e3e63e3e4e"
      },
      "source": [
        "gray_named = (img_named * weights_aligned).sum('channels')\n",
        "gray_named.shape, gray_named.names"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 5]), ('rows', 'columns'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSScOUnUAl8M",
        "outputId": "f289d0c9-325d-477f-90e8-5375b69aff68"
      },
      "source": [
        "gray_plain = gray_named.rename(None)\n",
        "gray_plain.shape, gray_plain.names"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 5]), (None, None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLa67akNA3uQ"
      },
      "source": [
        "# Tensor element Types\n",
        "- default data type for tensors is 32-bit floating-point. \n",
        "\n",
        "**floating-point**\n",
        "> *16-bit*\n",
        "*   not present natively in standard CPUS\n",
        "*   decreases the footprint of a neural netwokk model, with a minor impact on accuracy.\n",
        "\n",
        "> *32-bit*\n",
        "*   default\n",
        "\n",
        "> *64-bit*\n",
        "*   no improvements in the accuracy of a model\n",
        "*   require more memory, computing time\n",
        "\n",
        "**integer types**\n",
        "> 64-bit integer data type default.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuqd4cHQT1rn"
      },
      "source": [
        "# In-place operations\n",
        "> underscore exists: operates in-place/ 주어진 입력을 수정/변화시킴. 새로운 tensor를 생성하는 것이 아님.\n",
        "> no underscore: 입력 변화 없음. 새로운 변화된 tensor return."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7mT6Ma6KQQF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15e6c654-675e-4388-b3f4-462aef30b861"
      },
      "source": [
        "a = torch.ones(3,2)\n",
        "a.zero_()\n",
        "a"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CcdLooCUVf6"
      },
      "source": [
        "# Tensor metadata: Size, offset, and stride\n",
        "> *size*: is a tuple indecating how many elements acrross each dimension the tensor represents.\n",
        "\n",
        "> *storatge offset*: index in the storage corresponding to the first element in the tensor.\n",
        "\n",
        "> *stride*: number of elements in the storage that need to be skipped when the index is increased by 1 in each dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdIS-4tBKQOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1cfa6f3-84c9-4c02-e805-a55ba8ea7f65"
      },
      "source": [
        "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
        "second_point = points[1]\n",
        "second_point.storage_offset()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9zC3MekVciZ"
      },
      "source": [
        "# Clone\n",
        "maybe... deep copy?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoDdQUPPVlWL",
        "outputId": "1def6393-6e1b-472d-c113-f2e9f201340a"
      },
      "source": [
        "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
        "second_point = points[1].clone()\n",
        "second_point[0] = 10.0\n",
        "points# no change!"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4., 1.],\n",
              "        [5., 3.],\n",
              "        [2., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPcF9NcvWCmt"
      },
      "source": [
        "# Moving tensors to GPU\n",
        "\n",
        "*   speedups!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY_gqCL9WFJ5"
      },
      "source": [
        "points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device = 'cuda')\n",
        "# or copy a tensor created on the CPU onto the GPU using the to method.\n",
        "points_gpu = points.to(device = 'cuda')\n",
        "points_gpu = points.cuda()#default cuda:0\n",
        "\n",
        "#we can also decide on which GPU we allocate the tensor by passing a zero-based integer identifying the GPU on the machine\n",
        "points_gpu = points.to(device = 'cuda:0')\n",
        "points_gpu = points.cuda(0)\n",
        "\n",
        "# any operations performed on the tensor is carried out on the GPU\n",
        "#Moving back to CPU\n",
        "points_cpu = points_gpu.to(device = 'cpu')\n",
        "points_cpu = points_gpu.cpu()\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsGZ7nSoXkb7"
      },
      "source": [
        "# Numpy Interoperability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rtrx01TXnOM"
      },
      "source": [
        "#numpy -> tensor\n",
        "points = torch.ones(3,4)\n",
        "points_np = points.numpy()\n",
        "points_np\n",
        "\n",
        "#tensor-> numpy\n",
        "points = torch.from_numpy(points_np)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoHj_1uxKSL7"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "----\n",
        "1. what does view do?\n",
        "\n",
        "\n",
        "\n",
        "> 원하는 모양대로 배열을 재배치? 한다.\n",
        "a,b는 같은 storage를 공유한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikZMRQv0KQLW",
        "outputId": "c453bf74-0a9a-4d71-83fb-bc897ccd68a0"
      },
      "source": [
        "a = torch.tensor(list(range(9)))\n",
        "b = a.view(3,3)\n",
        "c = b[1:, 1:]\n",
        "print(a.size(), a.storage_offset(), a.stride())\n",
        "print(b.size(), b.storage_offset(), b.stride())\n",
        "print(c.size(), c.storage_offset(), c.stride())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([9]) 0 (1,)\n",
            "torch.Size([3, 3]) 0 (3, 1)\n",
            "torch.Size([2, 2]) 4 (3, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc27f747UPNb"
      },
      "source": [
        "#2. pick a mathematical operation like cosine or square root. can you find a corresponding function in the torch library?\n",
        "\n",
        "\n",
        "> ㅇㅇ : `torch.cos/torch.sin`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.   apply the function element-wise to a. why does it return an error?\n",
        "> 음... ㅎ...에러따위 뜨지 않는걸요...\n",
        "2.   what operation is required to make the function work?\n",
        "> 만약, 정수형이라서 생기는 에러라면, `.to(torch.double)` 을 붙여서 double 또는 float형으로 받아서 에러를 없앨 수 있습니다.\n",
        "\n",
        "> cf: while the default numeric type in pytorch is 32-bit floating-point, for NumPy it is 64-bit. As discussed in section 3.5.2, we usually want to use 32-bit floating-points, so we need to make sure we have tensors of dtype torch.float after converting.(not this case but the above numpy, tensor interchanging process and this problem seems quite simillar.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XieGkBfLYuns"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH6IDVfuTjFj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZYBiCNCfbgi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZlNHpBwXC-S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}