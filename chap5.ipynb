{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chap5.ipynb",
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyPK47A+dC6nplUUNXVsNbOj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tonge-Shim/pytorchstudy/blob/main/chap5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yME6a6Ob0x6t"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9-_BB5Nir_c"
      },
      "source": [
        "#celcius -> fahrenheit\n",
        "w = 5.5556, b = -17.7778"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODpzhQO30QqE"
      },
      "source": [
        "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
        "t_c = torch.tensor(t_c)\n",
        "t_u = torch.tensor(t_u)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcyNYp40NPRf"
      },
      "source": [
        "parameters will be pytorch scalars(zero-dimensional tensors)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGjcO6dJ04aP",
        "outputId": "b55b7568-8100-47f7-9bc8-9a7f46815151"
      },
      "source": [
        "def model(t_u, w, b):\n",
        "    return w * t_u +b\n",
        "#mean square loss\n",
        "def loss_fn(t_p, t_c):\n",
        "    squared_diffs = (t_p - t_c)**2\n",
        "    return squared_diffs.mean()\n",
        "#initialize parameters\n",
        "w = torch.ones(())\n",
        "b = torch.zeros(())\n",
        "\n",
        "t_p = model(t_u, w, b)\n",
        "print(t_p)\n",
        "loss = loss_fn(t_p, t_c)\n",
        "print(loss)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000, 21.8000,\n",
            "        48.4000, 60.4000, 68.4000])\n",
            "tensor(1763.8848)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozEHjHqMaeFQ"
      },
      "source": [
        "#delta에 따른 차이는?\n",
        "delta = 0.1\n",
        "loss_rate_of_change_w = (loss_fn(model(t_u, w+delta, b), t_c) - loss_fn(model(t_u, w-delta, b), t_c)) / (2.0*delta)\n",
        "loss_rate_of_change_b = (loss_fn(model(t_u, w, b+delta), t_c) - loss_fn(model(t_u, w, b-delta), t_c)) / (2.0*delta)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU5AHqoebMri"
      },
      "source": [
        "learning_rate = 1e-2\n",
        "w = w - learning_rate * loss_rate_of_change_w\n",
        "b = b - learning_rate * loss_rate_of_change_b"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz6kWkFkcq2s"
      },
      "source": [
        "#*the gradient*\n",
        "compute the individual derivatives of the loss with respect to each parameter and put them in a vector of defivatives: the gradient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJQhjb-Icssh"
      },
      "source": [
        "def dloss_fn(t_p, t_c):\n",
        "    dsq_diffs = 2*(t_p-t_c) / t_p.size(0)\n",
        "    return dsq_diffs\n",
        "def dmodel_dw(t_u, w, b):\n",
        "    return t_u\n",
        "def dmodel_db(t_u, w, b):\n",
        "    return 1.0\n",
        "def grad_fn(t_u, t_c, t_p, w, b):\n",
        "    dloss_dtp = dloss_fn(t_p, t_c)\n",
        "    dloss_dw = dloss_dtp * dmodel_dw(t_u, w, b)\n",
        "    dloss_db = dloss_dtp * dmodel_db(t_u, w, b)\n",
        "    return torch.stack([dloss_dw.sum(), dloss_db.sum()])#what is this stack function?\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO1obRQDecz2"
      },
      "source": [
        "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        w,b = params\n",
        "        t_p = model(t_u, w, b)\n",
        "        loss = loss_fn(t_p, t_c)\n",
        "        grad = grad_fn(t_u, t_c, t_p, w, b)\n",
        "\n",
        "        params = params - learning_rate * grad\n",
        "\n",
        "        #print(\"Epoch %d, Loss %f\" % (epoch, float(loss)))\n",
        "    return params\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0EU1JcyfbnF",
        "outputId": "597ccfe4-bba0-4e05-d25d-97ac55751c48"
      },
      "source": [
        "training_loop(n_epochs = 100, learning_rate = 1e-2, params = torch.tensor([1.0, 0.0]), t_u = t_u, t_c = t_c)\n",
        "#망..."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([nan, nan])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvlIspOdgD-s",
        "outputId": "1cd5d44c-ebe8-4b77-9dfd-49f65d86ec55"
      },
      "source": [
        "training_loop(n_epochs = 100, learning_rate = 1e-4, params = torch.tensor([1.0, 0.0]), t_u = t_u, t_c = t_c)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.2327, -0.0438])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GlCn9tchg8k"
      },
      "source": [
        "#changing the inputs so that the gradients aren't quite so different"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CESg3VJEhmea"
      },
      "source": [
        "t_un = 0.1 * t_u#normalized --> t_u + n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkqW50V1hwfg",
        "outputId": "81b86f52-ffe6-423e-b02a-5d38d65e479d"
      },
      "source": [
        "training_loop(n_epochs = 100, learning_rate = 1e-2, params = torch.tensor([1.0, 0.0]), t_u = t_un, t_c = t_c)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2.7553, -2.5162])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNc86uQ6iHnr"
      },
      "source": [
        "#epoch up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dqBFSJZiJNz"
      },
      "source": [
        "params = training_loop(n_epochs = 5000, learning_rate = 1e-2, params = torch.tensor([1.0, 0.0]), t_u = t_un, t_c = t_c)\n",
        "#nice"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z11Aspqi3E-"
      },
      "source": [
        "#visualizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMdrBRiHi4UL"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Uc-wgygnjCIL",
        "outputId": "fa185e17-2d48-4d13-fab2-124c080a1570"
      },
      "source": [
        "t_p = model(t_un, *params)#unpacking\n",
        "fig = plt.figure(dpi = 90)#이게 뭐고/size maybe\n",
        "plt.xlabel(\"Temperature (Fahrenheit)\")\n",
        "plt.ylabel(\"Temperature (Celcius)\")\n",
        "plt.plot(t_u.numpy(), t_p.detach().numpy())#result\n",
        "plt.plot(t_u.numpy(), t_c.numpy(), 'o')#inputs"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7efdc0c508d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 540x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbkZwdQ1nJR1"
      },
      "source": [
        "#Autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07lu2pvik786"
      },
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad = True)\n",
        "#requires_grad = True: track the entire family tree of tensors resulting \n",
        "#from operations on parmas."
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo9Mfcsynw73",
        "outputId": "5919bbce-6d77-4ab0-cdec-35f041ff3126"
      },
      "source": [
        "params.grad is None"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV-zq5Trn64y",
        "outputId": "2c9d6e10-166d-4719-a8a9-343090c56ba3"
      },
      "source": [
        "loss = loss_fn(model(t_u, *params), t_c)\n",
        "loss.backward()\n",
        "\n",
        "params.grad"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4517.2969,   82.6000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_zukf-apt7I"
      },
      "source": [
        "#backward\n",
        "calling backward will lead derivatives to *accumulate* at leaf nodes.\n",
        "so if backward was called earlier, the loss is evaluated again, backward is called again and the gradient at each lear is accumulated on top of the one computed at the previous iteration, which leads to an incorrect value for the gradient.\n",
        "\n",
        "\n",
        "> in order to prevent this from occuring, we need to zero the gradient explicitly at each iteration--> zero_ method\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "add7TWPnqiKz"
      },
      "source": [
        "if params.grad is not None:\n",
        "    params.grad.zero_()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L7HwRZ5qvfQ"
      },
      "source": [
        "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        if params.grad is not None:\n",
        "            params.grad.zero_()\n",
        "\n",
        "        t_p = model(t_u, *params)\n",
        "        loss = loss_fn(t_p, t_c)\n",
        "        loss.backward()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            params -= learning_rate * params.grad\n",
        "        \n",
        "        if epoch%500 == 0:\n",
        "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "\n",
        "    return params"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5Ows2JOeJlx",
        "outputId": "c8bc1593-56c1-475a-cebb-860aba039842"
      },
      "source": [
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    learning_rate = 1e-2,\n",
        "    params = torch.tensor([1.0, 0.0], requires_grad = True),\n",
        "    t_u = t_un, \n",
        "    t_c = t_c\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 500, Loss 7.860115\n",
            "Epoch 1000, Loss 3.828538\n",
            "Epoch 1500, Loss 3.092191\n",
            "Epoch 2000, Loss 2.957698\n",
            "Epoch 2500, Loss 2.933134\n",
            "Epoch 3000, Loss 2.928648\n",
            "Epoch 3500, Loss 2.927830\n",
            "Epoch 4000, Loss 2.927679\n",
            "Epoch 4500, Loss 2.927652\n",
            "Epoch 5000, Loss 2.927647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.3671, -17.3012], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_RgOfQXfTXb",
        "outputId": "7ac28344-73b3-46cd-8c89-0b0c75411fd9"
      },
      "source": [
        "import torch.optim as optim\n",
        "dir(optim)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ASGD',\n",
              " 'Adadelta',\n",
              " 'Adagrad',\n",
              " 'Adam',\n",
              " 'AdamW',\n",
              " 'Adamax',\n",
              " 'LBFGS',\n",
              " 'Optimizer',\n",
              " 'RMSprop',\n",
              " 'Rprop',\n",
              " 'SGD',\n",
              " 'SparseAdam',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_functional',\n",
              " '_multi_tensor',\n",
              " 'lr_scheduler',\n",
              " 'swa_utils']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua5C2iCWgv5q"
      },
      "source": [
        "#SGD\n",
        "stochastic gradient descent\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qcZgCXAgdU7"
      },
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-5\n",
        "optimizer = optim.SGD([params], lr = learning_rate)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZITBiAz9gxjm",
        "outputId": "03b5d97f-6db7-49d5-aee0-50f21fc857f5"
      },
      "source": [
        "t_p = model(t_u, *params)\n",
        "loss = loss_fn(t_p, t_c)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "params"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9.5483e-01, -8.2600e-04], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaYVxadWjejS",
        "outputId": "5f8211ed-540b-4541-8d52-02fd20eb845a"
      },
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD([params], lr = learning_rate)\n",
        "\n",
        "t_p = model(t_un, *params)\n",
        "loss = loss_fn(t_p, t_c)\n",
        "\n",
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "params"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.7761, 0.1064], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "182Bep4SkX0D",
        "outputId": "f8186d3d-3871-4e88-d3f4-a852044df899"
      },
      "source": [
        "def training_loop(n_epochs, optimizer, params, t_u, t_c):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        t_p = model(t_u, *params)\n",
        "        loss = loss_fn(t_p, t_c)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if epoch%500 == 0:\n",
        "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "\n",
        "    return params\n",
        "\n",
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD([params], lr = learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = optimizer,\n",
        "    params = params,\n",
        "    t_u = t_un, \n",
        "    t_c = t_c)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 500, Loss 7.860120\n",
            "Epoch 1000, Loss 3.828538\n",
            "Epoch 1500, Loss 3.092191\n",
            "Epoch 2000, Loss 2.957698\n",
            "Epoch 2500, Loss 2.933134\n",
            "Epoch 3000, Loss 2.928648\n",
            "Epoch 3500, Loss 2.927830\n",
            "Epoch 4000, Loss 2.927679\n",
            "Epoch 4500, Loss 2.927652\n",
            "Epoch 5000, Loss 2.927647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.3671, -17.3012], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXtqM3eTmYEM"
      },
      "source": [
        "#Adam\n",
        "sophisticated optimizer in which the learning rate is set adaptively. +, less sensitive to the scaling of the parameters--so insensitive that we can go back to using the original input t_u, and even increase the learning rate to 1e-1, and Adam won't even blink."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3M9QEhxkpoU",
        "outputId": "f8cf5fde-4313-4abe-99d7-0b477e6f84ca"
      },
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-1\n",
        "optimizer = optim.Adam([params], lr = learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 2000,\n",
        "    optimizer = optimizer,\n",
        "    params = params,\n",
        "    t_u = t_u, \n",
        "    t_c = t_c)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 500, Loss 7.612900\n",
            "Epoch 1000, Loss 3.086700\n",
            "Epoch 1500, Loss 2.928579\n",
            "Epoch 2000, Loss 2.927644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  0.5367, -17.3021], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wyfEk41rvHv"
      },
      "source": [
        "#cure for overfitting\n",
        "\n",
        "\n",
        "> 1. make sure we get enough data for the process\n",
        "> 2. make sure the model that is capable of fitting the training data is as regular as possible in between them\n",
        ">> add penalization terms to the loss function to make it cheaper for the model to behave more smoothly and change more slowly.\n",
        ">> add noise to the input samples and train them too\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUUYO7-Etv7b"
      },
      "source": [
        "#Shuffling a Dataset\n",
        "randperm function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWdAX_X4mvQE",
        "outputId": "02fd63bd-0bcc-44c0-ead9-be59d8c35b39"
      },
      "source": [
        "n_samples = t_u.shape[0]\n",
        "n_val = int(0.2 * n_samples)#11*0.2 = 2.2\n",
        "shuffled_indices = torch.randperm(n_samples)\n",
        "\n",
        "train_indices = shuffled_indices[:-n_val]# ~ -2끝에서 두번째 까지\n",
        "val_indices = shuffled_indices[-n_val:]# -2부터 끝까지\n",
        "\n",
        "train_indices, val_indices"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([5, 7, 1, 4, 3, 8, 2, 0, 6]), tensor([10,  9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jylP6XOvDZf"
      },
      "source": [
        "train_t_u = t_u[train_indices]\n",
        "train_t_c = t_c[train_indices]\n",
        "\n",
        "val_t_u = t_u[val_indices]\n",
        "val_t_c = t_c[val_indices]\n",
        "\n",
        "train_t_un = 0.1 * train_t_u\n",
        "val_t_un = 0.1 * val_t_u"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_7TGEY9vgyY",
        "outputId": "de8aca49-c11d-4f10-9094-d763b65631a3"
      },
      "source": [
        "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u, train_t_c, val_t_c):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        train_t_p = model(train_t_u, *params)\n",
        "        train_loss = loss_fn(train_t_p, train_t_c)\n",
        "\n",
        "        val_t_p = model(val_t_u, *params)\n",
        "        val_loss = loss_fn(train_t_p, train_t_c)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if epoch <= 3 or epoch%500 == 0:\n",
        "            print(f\"Epoch {epoch}, Training loss{train_loss.item():.4f},\"\n",
        "                  f\"Validation loss {val_loss.item(): .4f}\")\n",
        "\n",
        "    return params\n",
        "\n",
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD([params], lr = learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 3000,\n",
        "    optimizer = optimizer,\n",
        "    params = params,\n",
        "    train_t_u = train_t_un, \n",
        "    val_t_u = val_t_un,\n",
        "    train_t_c = train_t_c,\n",
        "    val_t_c = val_t_c)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Training loss70.5623,Validation loss  70.5623\n",
            "Epoch 2, Training loss40.3757,Validation loss  40.3757\n",
            "Epoch 3, Training loss34.2207,Validation loss  34.2207\n",
            "Epoch 500, Training loss7.1204,Validation loss  7.1204\n",
            "Epoch 1000, Training loss3.4128,Validation loss  3.4128\n",
            "Epoch 1500, Training loss2.8828,Validation loss  2.8828\n",
            "Epoch 2000, Training loss2.8070,Validation loss  2.8070\n",
            "Epoch 2500, Training loss2.7962,Validation loss  2.7962\n",
            "Epoch 3000, Training loss2.7946,Validation loss  2.7946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.3306, -17.0593], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}