{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chap2 cyclegan, neuraltalk.ipynb",
      "provenance": [],
      "mount_file_id": "196LszEMim09qmSmVVgx3T7dS5vAAB-wH",
      "authorship_tag": "ABX9TyPRcx+fOGOUmrZ3kvEfT+f2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tonge-Shim/pytorchstudy/blob/main/chap2_cyclegan%2C_neuraltalk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hBMKrjFmh00"
      },
      "source": [
        "# GAN\n",
        "*generative adversarial network*\n",
        "\n",
        "\n",
        "*   generative: 생산하는\n",
        "\n",
        "*   adversarial: 2개의 네트워크가 서로보다 똑똑해지려 경쟁\n",
        "\n",
        "*   networK; network\n",
        " \n",
        "**goal: to produce synthetic(인조의) examples of a class of images that cannot be recognized as fake**\n",
        "\n",
        "---\n",
        "*2 networks*\n",
        "\n",
        "\n",
        "> generator network: takes the role of the painter\n",
        "\n",
        "\n",
        "> discriminator network: amoral art inspector, needing to tell whether a given image was fabricated by the generator or belongs in a set of real images.\n",
        "\n",
        "*goal of generator: to fool the discriminator into mixing up real and fake images*\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aten7zjjmF8l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94ZrEVcLnPqs"
      },
      "source": [
        "# CycleGAN\n",
        "\n",
        "\n",
        "> a cyclegan can turn images of one domain into images of another domain, without the need for us to explicitly provide matching pairs in the training set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lVPk1PKp9Qh"
      },
      "source": [
        "코드는 나중에 배우는걸로..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ycddx7eDq-Bv"
      },
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import torch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FjzlBvKrFoz"
      },
      "source": [
        "preprocess = transforms.Compose([transforms.Resize(256),\n",
        "                                 transforms.ToTensor()])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hkdFVPerUef"
      },
      "source": [
        "img = Image.open('/content/drive/MyDrive/DLWP/horse.jpg')\n",
        "img_t = preprocess(img)\n",
        "batch_t = torch.unsqueeze(img_t,0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTEMvbbmsHSF"
      },
      "source": [
        "**`batch_t = torch.unsqueeze(img_t,0)`**\n",
        "\n",
        "\n",
        "> *unsqueeze:* Returns a new tensor with a dimension of size one inserted at the specified position.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtU8B7DUsqi1"
      },
      "source": [
        "batch_out = negG(batch_t)# negG: 이 코드엔 없지만 먼저 정의된 generator 모델.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F02HVWnps8DP"
      },
      "source": [
        "**batch_out**: output of the generator, which we can convert back to an image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZISTBBqs80G"
      },
      "source": [
        "out_t = (batch_out.data.squeeze() + 1.0) / 2.0\n",
        "out_img = transforms.ToPILImage()(out_t)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FP8mdDHtHrH"
      },
      "source": [
        "# various generators\n",
        "\n",
        "> capable of creating credible human faces of nonexisting individuals\n",
        "\n",
        "> translate sketches into real-looking pectures of imaginary landscapes\n",
        "\n",
        "> producing real-sounding audio, credible text, and enjoyable music\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhi9k-GCu8mK"
      },
      "source": [
        "# NeuralTalk2\n",
        "**natural language**\n",
        "> when presented with a natural image, this kind of model generates a caption in English that describes the scene.\n",
        "\n",
        "> *this model has 2 connected halves*\n",
        "\n",
        "> **the first half** of the model: a network that learns to generate \"descriptive\" numerical representations of the scene(Tabby cat, laser mouse, paw)\n",
        "\n",
        "> **the second half** of the model: recurrent neural network that generates a coherent sentence by putting those numerical descriptions together.\n",
        "\n",
        "*recurrent*: called recurrent because it generates its outputs in subsequent forward passes, where the input to each forward pass includes the outputs of the previous forward pass. this generates dependency of the next word on words that were generated earlier.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxeEvkqWwlhN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
